{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMMmyCmwiA0ed3OXw7RLuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch23s020/Assignment3/blob/main/RNN_withAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDlogW2NEp0s"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import gdown\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "TSOvm_JrYFLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the download URLs for Google Sheets as CSV\n",
        "\n",
        "train_url = \"https://docs.google.com/spreadsheets/d/11duz5Vbqay5TVn_uyglVQVcEZllTbWQt_8zTt2TcBSA/export?format=csv\"\n",
        "\n",
        "valid_url = \"https://docs.google.com/spreadsheets/d/1KbKFfxFkMddkZde0r5PWKnQ0vzdh-XihxsMP7XUFDJc/export?format=csv\"\n",
        "\n",
        "test_url = \"https://docs.google.com/spreadsheets/d/1ItKDweGPNtzWiF3rs0jzKjh7ZRRkas2hz7yWvbt4yzQ/export?format=csv\"\n",
        "\n",
        "# Paths to save the files\n",
        "\n",
        "train_output = 'train_data.csv'\n",
        "\n",
        "valid_output = 'valid_data.csv'\n",
        "\n",
        "test_output = 'test_data.csv'\n",
        "\n",
        "# Download the files\n",
        "\n",
        "gdown.download(train_url, train_output, quiet=False)\n",
        "\n",
        "gdown.download(valid_url, valid_output, quiet=False)\n",
        "\n",
        "gdown.download(test_url, test_output, quiet=False)\n",
        "\n",
        "# Function to load data\n",
        "\n",
        "def load_data(file_path):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
        "\n",
        "        csvreader = csv.reader(csvfile)\n",
        "\n",
        "        for idx, row in enumerate(csvreader):\n",
        "\n",
        "            try:\n",
        "                x = str(row[0])  # Assuming the first column contains Romanized strings\n",
        "\n",
        "                y = str(row[1])  # Assuming the second column contains Devanagari strings\n",
        "\n",
        "                data.append((x, y))\n",
        "\n",
        "            except IndexError:\n",
        "\n",
        "                print(f\"IndexError in row {idx + 1}: {row}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "\n",
        "train_data = load_data(train_output)\n",
        "\n",
        "valid_data = load_data(valid_output)\n",
        "\n",
        "test_data = load_data(test_output)\n",
        "\n",
        "# Data Preparation\n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, char2index, max_length=20):\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "        self.char2index = char2index\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x, y = self.data[idx]\n",
        "\n",
        "        x_indices = [self.char2index[c] for c in x] + [self.char2index['<PAD>']] * (self.max_length - len(x))\n",
        "\n",
        "        y_indices = [self.char2index[c] for c in y] + [self.char2index['<PAD>']] * (self.max_length - len(y))\n",
        "\n",
        "        return torch.tensor(x_indices), torch.tensor(y_indices), len(x), len(y)\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    x, y, x_lengths, y_lengths = zip(*batch)\n",
        "\n",
        "    x = torch.nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=char2index['<PAD>'])\n",
        "\n",
        "    y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=char2index['<PAD>'])\n",
        "\n",
        "    return x, y, x_lengths, y_lengths\n",
        "\n",
        "# Create character to index mappings\n",
        "\n",
        "all_chars = sorted(set(''.join([x for x, y in train_data + valid_data + test_data]) + ''.join([y for x, y in train_data + valid_data + test_data])))\n",
        "\n",
        "char2index = {char: idx for idx, char in enumerate(all_chars)}\n",
        "\n",
        "char2index['<PAD>'] = len(char2index)\n",
        "\n",
        "char2index['<SOS>'] = len(char2index) + 1\n",
        "\n",
        "char2index['<EOS>'] = len(char2index) + 2\n"
      ],
      "metadata": {
        "id": "mHHqY4E0YKS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb\n",
        "sweep_config = {\n",
        "    \"method\": \"random\",\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\": {\"values\": [0.001, 0.01, 0.1]},\n",
        "        \"batch_size\": {\"values\": [32]},\n",
        "        \"num_epochs\": {\"values\": [5, 10, 15, 20]},\n",
        "        \"encoder_layers\": {\"values\": [1]},\n",
        "        \"decoder_layers\": {\"values\": [1]},\n",
        "        \"hidden_dim\": {\"values\": [128, 256, 512]},\n",
        "        \"embedding_dim\": {\"values\": [128, 256, 512]},\n",
        "        \"dropout_rate\": {\"values\": [0, 0.1, 0.2]},\n",
        "        \"rnn_cell_type\": {\"values\": [\"lstm\", \"rnn\", \"gru\"]},\n",
        "        \"bidirectional\": {\"values\": [False]},\n",
        "        \"max_length\": {\"values\": [20, 60, 100, 150]},\n",
        "        \"gradient_clip\": {\"values\": [1, 2]},\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Assign3_withattention\")\n",
        "\n",
        "\n",
        "\n",
        "# For Best Model Accuracy to get Test Data Uncomment The following Code.\n",
        "\n",
        "\n",
        "# # Initialize wandb\n",
        "# sweep_config = {\n",
        "#     \"method\": \"random\",\n",
        "#     \"parameters\": {\n",
        "#         \"learning_rate\": {\"values\": [0.001]},\n",
        "#         \"batch_size\": {\"values\": [32]},\n",
        "#         \"num_epochs\": {\"values\": [15]},\n",
        "#         \"encoder_layers\": {\"values\": [2]},\n",
        "#         \"decoder_layers\": {\"values\": [2]},\n",
        "#         \"hidden_dim\": {\"values\": [128]},\n",
        "#         \"embedding_dim\": {\"values\": [128]},\n",
        "#         \"dropout_rate\": {\"values\": [0]},\n",
        "#         \"rnn_cell_type\": {\"values\": [\"gru\"]},\n",
        "#         \"bidirectional\": {\"values\": [False]},\n",
        "#         \"max_length\": {\"values\": [100]},\n",
        "#         \"gradient_clip\": {\"values\": [1]},\n",
        "#     }\n",
        "# }\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"Assign3_withattention\")\n"
      ],
      "metadata": {
        "id": "0sTrv8FfYKb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create datasets and dataloaders\n",
        "\n",
        "train_dataset = TransliterationDataset(train_data, char2index)\n",
        "\n",
        "valid_dataset = TransliterationDataset(valid_data, char2index)\n",
        "\n",
        "test_dataset = TransliterationDataset(test_data, char2index)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
        "\n"
      ],
      "metadata": {
        "id": "1H7scLeBYKdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model Components\n",
        "\n",
        "class EmbeddingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim):\n",
        "\n",
        "        super(EmbeddingLayer, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.embedding(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim):\n",
        "\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        max_len = encoder_outputs.size(1)\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, max_len, 1)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), 2)))\n",
        "\n",
        "        energy = energy.permute(0, 2, 1)\n",
        "\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "\n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, dropout, rnn_type='lstm', bidirectional=False):\n",
        "\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        self.embedding = EmbeddingLayer(input_dim, embedding_dim)\n",
        "\n",
        "        rnn_cls = {'rnn': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}[rnn_type]\n",
        "\n",
        "        self.rnn = rnn_cls(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        outputs, hidden = self.rnn(x)\n",
        "\n",
        "        if self.bidirectional:\n",
        "\n",
        "            if isinstance(hidden, tuple):  # LSTM\n",
        "\n",
        "                hidden = (self._concat_hidden(hidden[0]), self._concat_hidden(hidden[1]))\n",
        "\n",
        "            else:  # RNN or GRU\n",
        "\n",
        "                hidden = self._concat_hidden(hidden)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "    def _concat_hidden(self, hidden):\n",
        "\n",
        "        return torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1).unsqueeze(0)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim, embedding_dim, hidden_dim, num_layers, dropout, attention, rnn_type='lstm'):\n",
        "\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.embedding = EmbeddingLayer(output_dim, embedding_dim)\n",
        "\n",
        "        rnn_cls = {'rnn': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}[rnn_type]\n",
        "\n",
        "        self.rnn = rnn_cls(embedding_dim + hidden_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        self.attention = attention\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs):\n",
        "\n",
        "        x = self.embedding(x).unsqueeze(1)\n",
        "\n",
        "        attn_weights = self.attention(hidden[-1], encoder_outputs)\n",
        "\n",
        "        attn_weights = attn_weights.unsqueeze(1)\n",
        "\n",
        "        context = attn_weights.bmm(encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((x, context), 2)\n",
        "\n",
        "        outputs, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        predictions = self.fc(torch.cat((outputs.squeeze(1), context.squeeze(1)), 1))\n",
        "\n",
        "        return predictions, hidden, attn_weights.squeeze(1)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        trg_len = trg.size(1)\n",
        "\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        output_dim = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        output = trg[:, 0]\n",
        "\n",
        "        attn_weights_all = []\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, attn_weights = self.decoder(output, hidden, encoder_outputs)\n",
        "\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            output = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        "            attn_weights_all.append(attn_weights.cpu().detach().numpy())\n",
        "\n",
        "        return outputs, attn_weights_all\n",
        "\n"
      ],
      "metadata": {
        "id": "udQc2AwmYXXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training functions\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg, src_len, trg_len) in enumerate(iterator):\n",
        "\n",
        "        src = src.to(model.device)\n",
        "\n",
        "        trg = trg.to(model.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output, _ = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (src, trg, src_len, trg_len) in enumerate(iterator):\n",
        "\n",
        "            src = src.to(model.device)\n",
        "\n",
        "            trg = trg.to(model.device)\n",
        "\n",
        "            output, _ = model(src, trg, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n"
      ],
      "metadata": {
        "id": "AayxQzR1YXZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def test(model, iterator, criterion, char2index, index2char):\n",
        "\n",
        "#     model.eval()\n",
        "\n",
        "#     epoch_loss = 0\n",
        "\n",
        "#     predictions = []\n",
        "\n",
        "#     ground_truths = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (src, trg, src_len, trg_len) in enumerate(iterator):\n",
        "\n",
        "#             src = src.to(model.device)\n",
        "\n",
        "#             trg = trg.to(model.device)\n",
        "\n",
        "#             output, attn_weights_all = model(src, trg, 0)\n",
        "\n",
        "#             output_dim = output.shape[-1]\n",
        "\n",
        "#             output = output[:, 1:].reshape(-1, output_dim)\n",
        "\n",
        "#             trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "#             loss = criterion(output, trg)\n",
        "\n",
        "#             epoch_loss += loss.item()\n",
        "\n",
        "#             preds = output.argmax(1).cpu().numpy()\n",
        "\n",
        "#             trg_cpu = trg.cpu().numpy()\n",
        "\n",
        "#             predictions.extend(preds)\n",
        "\n",
        "#             ground_truths.extend(trg_cpu)\n",
        "\n",
        "#             # Ensure the attention weights and source sequences align\n",
        "\n",
        "#             for b in range(len(attn_weights_all)):\n",
        "\n",
        "#                 fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "#                 sns.heatmap(attn_weights_all[b], ax=ax, cmap='viridis')\n",
        "\n",
        "#                 ax.set_xlabel('Encoder Steps')\n",
        "\n",
        "#                 ax.set_ylabel('Decoder Steps')\n",
        "\n",
        "#                 ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "#                 ax.yaxis.set_major_locator(ticker.MultipleLocator(1)\n",
        ")\n",
        "#                 plt.title(f'Attention Heatmap for Sample {i}-{b}')\n",
        "\n",
        "#                 wandb.log({f\"Attention Heatmap {i}-{b}\": wandb.Image(fig)})\n",
        "\n",
        "#                 plt.close(fig)\n",
        "\n",
        "#     # Log predictions and ground truths to wandb\n",
        "\n",
        "#     prediction_strings = [''.join([index2char[idx] for idx in pred if idx in index2char]) for pred in predictions]\n",
        "\n",
        "#     ground_truth_strings = [''.join([index2char[idx] for idx in truth if idx in index2char]) for truth in ground_truths]\n",
        "\n",
        "#     table = wandb.Table(data=[(pred, truth) for pred, truth in zip(prediction_strings, ground_truth_strings)],\n",
        "#                         columns=[\"Prediction\", \"Ground Truth\"])\n",
        "\n",
        "#     wandb.log({\"Predictions vs Ground Truths\": table})\n",
        "\n",
        "#     return epoch_loss / len(iterator)\n",
        "\n",
        "def test(model, iterator, criterion, char2index, index2char):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    ground_truths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (src, trg, src_len, trg_len) in enumerate(iterator):\n",
        "\n",
        "            src = src.to(model.device)\n",
        "\n",
        "            trg = trg.to(model.device)\n",
        "\n",
        "            output, attn_weights_all = model(src, trg, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            preds = output.argmax(1).cpu().numpy()\n",
        "\n",
        "            trg_cpu = trg.cpu().numpy()\n",
        "\n",
        "            predictions.extend(preds)\n",
        "\n",
        "            ground_truths.extend(trg_cpu)\n",
        "\n",
        "            # Ensure the attention weights and source sequences align\n",
        "\n",
        "            for b in range(src.size(0)):\n",
        "\n",
        "                fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "                sns.heatmap(attn_weights_all[b][:len(trg_len[b]), :len(src_len[b])], ax=ax, cmap='viridis')\n",
        "\n",
        "                ax.set_xlabel('Encoder Steps')\n",
        "\n",
        "                ax.set_ylabel('Decoder Steps')\n",
        "\n",
        "                ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "                plt.title(f'Attention Heatmap for Sample {i}-{b}')\n",
        "\n",
        "                wandb.log({f\"Attention Heatmap {i}-{b}\": wandb.Image(fig)})\n",
        "\n",
        "                plt.close(fig)\n",
        "\n",
        "    # Log predictions and ground truths to wandb\n",
        "\n",
        "    prediction_strings = [''.join([index2char[idx] for idx in pred if idx in index2char]) for pred in predictions]\n",
        "\n",
        "    ground_truth_strings = [''.join([index2char[idx] for idx in truth if idx in index2char]) for truth in ground_truths]\n",
        "\n",
        "    table = wandb.Table(data=[(pred, truth) for pred, truth in zip(prediction_strings, ground_truth_strings)],\n",
        "                        columns=[\"Prediction\", \"Ground Truth\"])\n",
        "\n",
        "    wandb.log({\"Predictions vs Ground Truths\": table})\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n"
      ],
      "metadata": {
        "id": "H053a-kjYXbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Ensure that the run_sweep function includes wandb logging and attention heatmap generation\n",
        "\n",
        "# def run_sweep(config=None):\n",
        "\n",
        "#     with wandb.init(config=config):\n",
        "\n",
        "#         config = wandb.config\n",
        "\n",
        "#         input_dim = len(char2index)\n",
        "\n",
        "#         output_dim = len(char2index)\n",
        "\n",
        "#         embedding_dim = config.embedding_dim\n",
        "\n",
        "#         hidden_dim = config.hidden_dim\n",
        "\n",
        "#         num_layers = config.encoder_layers\n",
        "\n",
        "#         dropout = config.dropout_rate\n",
        "\n",
        "#         rnn_type = config.rnn_cell_type\n",
        "\n",
        "#         bidirectional = config.bidirectional\n",
        "\n",
        "#         max_length = config.max_length\n",
        "\n",
        "#         attention = Attention(hidden_dim)\n",
        "\n",
        "#         encoder = EncoderRNN(input_dim, embedding_dim, hidden_dim, num_layers, dropout, rnn_type, bidirectional)\n",
        "\n",
        "#         decoder = DecoderRNN(output_dim, embedding_dim, hidden_dim, config.decoder_layers, dropout, attention, rnn_type)\n",
        "\n",
        "#         model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "#         optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "#         criterion = nn.CrossEntropyLoss(ignore_index=char2index['<PAD>'])\n",
        "\n",
        "#         best_valid_loss = float('inf')\n",
        "\n",
        "#         for epoch in range(config.num_epochs):\n",
        "\n",
        "#             train_loss = train(model, train_loader, optimizer, criterion, config.gradient_clip)\n",
        "\n",
        "#             valid_loss = evaluate(model, valid_loader, criterion)\n",
        "\n",
        "#             wandb.log({\"Train Loss\": train_loss, \"Valid Loss\": valid_loss})\n",
        "\n",
        "#             if valid_loss < best_valid_loss:\n",
        "\n",
        "#                 best_valid_loss = valid_loss\n",
        "\n",
        "#                 torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "#         model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "#         test_loss = test(model, test_loader, criterion, char2index, index2char)\n",
        "\n",
        "#         wandb.log({\"Test Loss\": test_loss})\n",
        "\n",
        "def run_sweep(config=None):\n",
        "\n",
        "    with wandb.init(config=config):\n",
        "\n",
        "        config = wandb.config\n",
        "\n",
        "        input_dim = len(char2index)\n",
        "\n",
        "        output_dim = len(char2index)\n",
        "\n",
        "        embedding_dim = config.embedding_dim\n",
        "\n",
        "        hidden_dim = config.hidden_dim\n",
        "\n",
        "        num_layers = config.encoder_layers\n",
        "\n",
        "        dropout = config.dropout_rate\n",
        "\n",
        "        rnn_type = config.rnn_cell_type\n",
        "\n",
        "        bidirectional = config.bidirectional\n",
        "\n",
        "        max_length = config.max_length\n",
        "\n",
        "        attention = Attention(hidden_dim)\n",
        "\n",
        "        encoder = EncoderRNN(input_dim, embedding_dim, hidden_dim, num_layers, dropout, rnn_type, bidirectional)\n",
        "\n",
        "        decoder = DecoderRNN(output_dim, embedding_dim, hidden_dim, config.decoder_layers, dropout, attention, rnn_type)\n",
        "\n",
        "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=char2index['<PAD>'])\n",
        "\n",
        "        best_valid_loss = float('inf')\n",
        "\n",
        "        for epoch in range(config.num_epochs):\n",
        "\n",
        "            train_loss = train(model, train_loader, optimizer, criterion, config.gradient_clip)\n",
        "\n",
        "            valid_loss = evaluate(model, valid_loader, criterion)\n",
        "\n",
        "            wandb.log({\"Train Loss\": train_loss, \"Valid Loss\": valid_loss})\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "\n",
        "                best_valid_loss = valid_loss\n",
        "\n",
        "                torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "        model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "        test_loss = test(model, test_loader, criterion, char2index, index2char)\n",
        "\n",
        "        wandb.log({\"Test Loss\": test_loss})\n",
        "\n",
        "        # Save predictions to CSV\n",
        "\n",
        "        save_predictions_to_csv(predictions, ground_truths, 'predictions_vs_ground_truths.csv', index2char)\n",
        "\n",
        "# Ensure all other required functions and classes are defined here\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "index2char = {v: k for k, v in char2index.items()}\n",
        "\n",
        "wandb.agent(sweep_id, run_sweep, count=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FZsrdkGQYXem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all other required functions and classes are defined here\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "index2char = {v: k for k, v in char2index.items()}\n"
      ],
      "metadata": {
        "id": "eyt3ys0KYKfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, run_sweep, count=1)"
      ],
      "metadata": {
        "id": "aqKifYbMYKio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}